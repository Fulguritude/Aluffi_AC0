Multiversity Algebra Chapter 0 Reading Group

Exercise solutions

Chapter I)

Section 1)

1.1)

In a nutshell, Russell’s paradox proves, by contradiction, that certain
mathematical collections cannot be sets. It posits the existence of a
"set of all sets that don’t contain themselves". Such a set can neither
contain itself (since in that case, it would be a "set that does contain
itself", and should be excluded); nor can it exclude it itself (since in
that case, it would be a "set that doesn’t contain itself", and should
be included).

1.2)

Prove that any equivalence relation over a set S defines a partition of
𝒫_(S).

a) 𝒫_(S) has no empty elements: any element in S is part of at least one
equivalence class, the class containing at least that element itself.
Since there is no equivalence class constructed independently from
elements, there are no empty equivalence classes.

b) Elements of 𝒫_(S) are disjoint: suppose there is an element x that is
part of A and B, two distinct equivalence classes. ∀a ∈ A, x ∼ a and
∀b ∈ B, x ∼ b. By transivity through x, ∀a ∈ A, ∀b ∈ B, a ∼ b.
Therefore, A and B are the same equivalence class: A = B. Contradiction.
Therefore all elements of 𝒫_(S) are disjoint subsets of S.

c) The union of all elements of 𝒫_(S) makes up S: suppose ∃x ∈ S such
that x ∉ ⋃_(S_(i) ∈ 𝒫_(S))S_(i). From the argument made in (a), x exists
in at least one equivalence class, the class which contains only x
itself. This is one of ou S_(i) sets. Contradiction. Therefore,
⋃_(S_(i) ∈ 𝒫_(S))S_(i) = S

1.3)

Given a partition 𝒫 on a set S, show how to define a relation ∼ on S
such that P is the corresponding partition.

The insight here is to build an equivalence relation such that two
elements are equivalent if and only if they are part of the same subset
of S, which is understood as their common equivalence class.

We define ∼ such that
∀S_(i), S_(j) ∈ 𝒫, ∀x ∈ S_(i), ∀y ∈ S_(j), x ∼ y ⇔ S_(i) = S_(j).

Let us prove that ∼ is an equivalence relation.

a) Reflexivity:
∀A ∈ 𝒫, ∀x ∈ A, A = A ⇒ x ∼ x

b) Symmetry:
∀S_(i), S_(j) ∈ 𝒫, ∀x ∈ S_(i), ∀y ∈ S_(j), x ∼ y ⇔ S_(i) = S_(j) ⇔ S_(j) = S_(i) ⇔ y ∼ x

c) Transitivity:

$$\begin{aligned}
\forall S_i, S_j, S_k \in \mathcal{P}, \forall x \in S_i, \forall y \in S_j, \forall z \in S_k, \\
(x \sim y) \cap (y \sim z) \\
    \Leftrightarrow \\
(S_i = S_j) \cap (S_j = S_k) \\
    \Rightarrow \\
S_i = S_k \\
    \Leftrightarrow \\
x \sim z
\end{aligned}$$

Therefore, ∼ is indeed an equivalence relation, and is generated
uniquely by the partition.

1.4)

How many different equivalence relations may be defined on the set
{1, 2, 3}?

If we start with the 1 element set, we have only one possible partition,
one possible equivalence class.

With the 2 element set, there are 2 partitions, {{1, 2}} and {{1}, {2}}.

With the 3 element set, there is:

-   1 partition of type 1-1-1: {{1}, {2}, {3}}.

-   3 partitions of type 2-1: {{1}, {2, 3}}, {{2}, {1, 3}}, and
    {{3}, {1, 2}}.

-   1 partition of type 3: {{1, 2, 3}}.

Hence, there are five equivalence classes on the 3 element set.

See the Bell numbers: https://oeis.org/A000110

1.5)

Give an example of a relation that is reflexive and symmetric, but not
transitive. What happens if you attempt to use this relation to define a
partition on the set?

Let’s imagine a "similarity relation" we can notate with ≃. We can
imagine it to work like a looser version of equality (say for example,
if an integer is only 1 away, then it counts as similar).

-   reflexive: ∀a ∈ S, a ≃ a (an element is always "similar" to itself)

-   symmetric: ∀a, b ∈ S, a ≃ b ⇒ b ≃ a ("similarity" goes both ways)

-   not transitive: ∃a, b, c ∈ S, (a ≃ b) ∧ (b ≃ c) ∧ ¬(a ≃ c) (just
    because a ≃ b and b ≃ c are similar, that doesn’t mean a ≃ c works,
    because it is possible for the "similarity gap" to be too large to
    qualify as "similar". E.g.: (a, b, c) = (1, 2, 3).).

If we use this to define a partition P on some set S: S/ ≃  := P_(≃),
there is ambiguity as to which element should go into which equivalence
class.

This idea deserves further discussion.

In terms of graph theory, if we express a set with an internal relation
as a graph, we can represent elements as nodes and relationships as
edges. Reflexivity means that every node has a loop (unary, self-edge).
Symmetry means that the graph is not directed (since every relationship
goes both ways). Transitivity means that every connected subset of nodes
is a maximal clique (synonymously, every connected component is a
complete subgraph).

In a relation which is reflexive and symmetric, but not transitive, you
would have connected components of this graph which are not cliques. For
these, there is ambiguity as to how you would group their nodes. Two
obvious choices would be either:

-   to remove the minimal number of edges to obtain n distinct cliques
    (thereby gaining the transitive restriction of the relation) from a
    given non-clique; or

-   to complete the connected subgraph into a clique (thereby gaining
    the transitive closure of the relation).

1.6)

Define a relation ∼ on the set ℝ of real numbers, by setting
a ∼ b ⇔ b − a ∈ ℤ. Prove that this is an equivalence relation, and find
a ’compelling’ description for ℝ/∼. Do the same for the relation ≈ on
the plane ℝ × ℝ defined by declaring
(a₁, a₂) ≈ (b₁, b₂) ⇔ b₁ − a₁ ∈ ℤ and b₂ − a₂ ∈ ℤ.

TODO: forgot to prove that it’s an equivalence relation

b − a ∈ ℤ means that 2 real numbers differ by an integral amount. This
means that the equivalence relation algebraically describes the idea
that "with this relation, 2 real numbers are the same iff they have the
same fractional component x (or 1 − x for negative numbers)". Eg,
4.76 ∼ 1024.76 ∼  − 5.34, since  − 5.34 + 10 = 4.76, etc.

To make an algebraic quotient of a set by an equivalence relation, we
take the function which maps each element to its corresponding
equivalence class, in the set (partition) containing these equivalence
class. Intuitively, this is similar to keeping only one representative
element per equivalence class. For the example class above, we can keep
the representative 0.76. There is such an equivalence class for every
fractional part possible, that is, one for every number in [0, 1[. The
corresponding map is the "real remainder of division modulo 1". This map
is well-defined because each real number has only one output for this
map, and all real numbers that are equivalent through ∼ are mapped to
the same value in the output set.

We should also notice that since 0 ∼ 1, this space loops around on
itself. Intuitively, if you increase linearly in the input space ℝ, it
goes back to 0 after 0.9999999... in the output space. This output space
is thus a circle of perimeter 1.

Similarly, b₁ − a₁ ∈ ℤ and b₂ − a₂ ∈ ℤ means that 2 points in the 2D
plane are the same iff they differ in each coordinate by an integral
amount. This boils down to combining two such loops from the first part
of the exercise: one in the x direction and one in the y direction: what
this gives is the small square [0, 1[ × [0, 1[, which loops to x = 0
(resp. y = 0) when x = 1 (resp. y = 1) is reached. This space functions
like a small torus, of area 1.

Section 2)

2.1)

How many different bijections are there between a set S with n elements
and itself?

Any bijection is a choice of a pairs from 2 sets of the same size, where
each element is used only once, and each pair has one element from each
set. At first there are n choices in each set. We go through each
possible input element in order (no choice), for each one, we pick one
amongst n possibilities for an output.

There are then (n − 1) choice of output left, etc.

Ccl°: $\prod_{i=1}^{i=n} i = n!$

2.2)

Prove that a function has a right-inverse (pre-inverse) iff it is
surjective (can use AC).

Let f ∈ (A → B).

2.2.a) ⇒

Suppose that f has a right-inverse (pre-inverse). We have
∃g ∈ (B → A), f ∘ g = id_(B)

Suppose that f is not a surjection. This means ∃b ∈ B, ∄a ∈ A, b = f(a)

f(g(b)) = id_(B)(b) = b Necessarily, g(b) is such an a, so
∃a ∈ A, b = f(a). Contradiction.

Ccl°:: f is a surjection.

2.2.b) ⇐

Suppose that f is a surjection.

∀b ∈ B, ∃a ∈ A, b = f(a)

We will construct a pre-inverse for f.

The insight here is to realize that a surjection divides its input set
into a partition, where each 2-by-2 disjoint subset corresponds to
f^( − 1)({q}), for every q in the output set. More formally, each
"fiber" (preimage of a singleton) is a disjoint subset of the input set,
and the union of fibers is the input set itself. You can see this in the
following diagram:

(add diagram) 1234 to ab 1a 2a (fiber from a) 3b 4b (fiber from b)
https://tex.stackexchange.com/questions/157450/producing-a-diagram-showing-relations-between-sets
https://tex.stackexchange.com/questions/79009/drawing-the-mapping-of-elements-for-sets-in-latex

Using AC, we select a single element from each such fiber. For each
q ∈ B, we name p_(q) ∈ f^( − 1)({q}) the chosen element. We define g as
g ∈ (B → A), g = (q ↦ p_(q)). With this, ∀b ∈ B, f ∘ g(b) = b, and so
f ∘ g = id_(A). Thus, f has a preinverse.

A summary of this idea: all surjection preinverses are simply a choice
of a representative for each fiber of the surjection as the output to
the respective singleton.

2.3)

Prove that the inverse of a bijection is a bijection, and that the
composition of two bijections is a bijection.

2.3.a)

Using the fact that a function is a bijection iff it has a two-sided
inverse (Corollary 2.2) we can see from this defining fact,
f ∈ (A → B) bijective  ⇔ ∃f^( − 1) ∈ (B → A), (f^( − 1) ∘ f = id_(A) and f ∘ f^( − 1) = id_(B))
that f is naturally f^( − 1)’s (unique) two-sided inverse, and so
f^( − 1) is also a bijection.

2.3.b)

Let be f ∈ (A → B), g ∈ (B → C), both bijective (hence with inverses in
the respective function spaces). Let h ∈ (A → C), h = g ∘ f and
h^( − 1) ∈ (C → A), h^( − 1) = f^( − 1) ∘ g^( − 1). We have:

$$\begin{aligned}
h^{-1} \circ h &= (f^{-1} \circ g^{-1}) \circ (g \circ f) \\
               &=  f^{-1} \circ g^{-1}  \circ  g \circ f  \\
               &=  f^{-1} \circ          id_B    \circ f  \\
               &=  f^{-1} \circ                        f  \\
               &=  id_A
\end{aligned}$$

$$\begin{aligned}
h \circ h^{-1} &= (g \circ f) \circ (f^{-1} \circ g^{-1}) \\
               &=  g \circ f  \circ  f^{-1} \circ g^{-1}  \\
               &=  g \circ     id_B         \circ g^{-1}  \\
               &=  g \circ                        g^{-1}  \\
               &=  id_C
\end{aligned}$$

Therefore h and h^( − 1) are two-sided inverses of each other, and thus
bijections. From this we conclude that the composition of any two
bijections is also a bijection.

2.4)

Prove that ‘isomorphism’ is an equivalence relation (on any set of
sets).

2.4.a) Problem statement

Let 𝒜 be a set of sets. We define the relation ≃ between the elements of
𝒜 as the following:

∀X, Y ∈ 𝒜, X ≃ Y ⇔ there exists a bijection between X and Y

Let us show that ≃ is an equivalence relation.

2.4.b) Reflexivity

For any set A ∈ 𝒜, the identity mapping on A is a bijection. This means
that ∀A ∈ 𝒜, A ≃ A, ie, ≃ is reflexive.

2.4.c) Symmetry

$$\begin{aligned}
\forall X, Y \in \mathcal{A}, \; X \simeq Y & \Rightarrow \exists f      \in (X \to Y) \text{ bijective} \\
                                            & \Rightarrow \exists f^{-1} \in (Y \to X) \text{ bijective} \\
                                            & \Rightarrow Y \simeq X
\end{aligned}$$

Therefore, ≃ is symmetric.

2.4.d) Transitivity

Let be X, Y, Z ∈ 𝒜. Suppose that X ≃ Y and Y ≃ Z. This means
∃f ∈ (X → Y), g ∈ (Y → Z), both bijections. Let be
h ∈ (X → Z), h = g ∘ f. h is also a bijection since the composition of
two bijections is also a bijection (exercise 2.3).

The existence of h implies X ≃ Z.

Therefore ≃ is transitive.

2.4.e) Conclusion

Isomorphism, ≃, is a relation on an arbitrary set (of sets) which is
always reflexive, symmetric and transitive. It is thus an equivalence
relation.

2.5)

Formulate a notion of epimorphism and prove that epimorphisms and
surjections are equivalent.

See "notes" file: section "Proofs of mono/inj and epi/surj equivalence".

2.6)

With notation as in Example 2.4, explain how any function f ∈ (A → B)
determines a section of π_(A).

A section is the preinverse of a surjection. Here, the surjection in
question is π_(A) the projection of A × B onto A.

Let f ∈ (A → B).

We now consider the function which maps an input a ∈ A of f to its
"geometric representation" (its coordinates in the enclosing space
A × B, corresponding to a point of the graph Γ_(f)).
f̂ ∈ (A → (A × B)), f̂ = ( a ↦ (a, f(a)) )
We notice that f̂(A) = Γ_(f).

Naturally, π_(A) ∘ f̂ = (a ↦ a) = id_(A), therefore, f̂ is a pre-inverse
(section) of π_(A).

This set of relationships can be expressed in the following commutative
diagram:

PS: see "On sections and fibers" in the "notes" file for a worked
example.

2.7)

Let f ∈ (A → B) be any function. Prove that the graph Γ_(f) of f is
isomorphic to A.

Using the elements from the previous exercise, we know that f̂ is
injective from A into A × B. This property is inherited to any
restriction of the codomain Z ⊆ A × B, and corresponding implied
restriction of the domain to Y = f̂^( − 1)(Z) ⊆ A. In particular, here,
Y = A and Z = Γ_(f) = f̂(A). We now consider
$\overline{f} \in (A \to \Gamma_f), \overline{f} = (a \mapsto \hat{f}(a))$.
We can see that $\overline{f}$ is injective from being a restriction of
an injective function to a smaller codomain. We also know that
$\overline{f}$ is surjective, since its domain is its image. Therefore,
$\overline{f}$ is a bijection. This means that A ≃ Γ_(f).

2.8)

Describe as explicitly as you can all terms in the canonical
decomposition of the function f ∈ (ℝ → ℂ) defined by f = (r ↦ e^(2πir)).
(This exercise matches one assigned previously, which one?)

Firstly, elements of ℝ are equivalent by this map (they have the same
output) if they vary by 1 from each other. This is a reference to the
equivalence relation ∼ in exercise 1.6. Therefore, we will use
ℝ/ ∼  ≃ S¹ in our decomposition. Obviously, the map from (ℝ → ℝ/ ∼ ),
which maps each element of ℝ to respective their equivalence class is a
surjection (since there’s no empty equivalence class).

Secondly, as mentioned, we have a bijection f̃ between ℝ/∼ and S¹, the
circle group of unit complex numbers, namely f̃ = (x ↦ e^(2πix), where
each element x of ℝ/∼ can be understood to correspond to a (class
representative) value in the interval [0, 1[.

Finally, we do the canonical injection of S¹ into its superset ℂ.

2.9)

Show that if A ≃ A′ and B ≃ B′ , and further A ∩ B = ∅ and A′ ∩ B′ = ∅,
then A ∪ B ≃ A′ ∪ B′. Conclude that the operation A∐B (as described in
§1.4) is well-defined up to isomorphism.

We suppose the aforementioned.

Let f_(A) be a bijection from A → A′, and f_(B) be a bijection from
B → B′.

We define the following:

$$f \in (A \cup B \to A' \cup B'),
\text{ such that }
\begin{cases}
    \forall a \in A, \; f(a) = f_A(a) \\
    \forall b \in B, \; f(b) = f_B(b)
\end{cases}$$

This function is a well-defined function, since A ∩ B = ∅: every element
of the domain has one, and only one, possible image.

Similarly, we define:

$$g \in (A' \cup B' \to A \cup B),
\text{ such that }
\begin{cases}
    \forall a \in A', \; g(a) = f_A^{-1}(a) \\
    \forall b \in B', \; g(b) = f_B^{-1}(b)
\end{cases}$$

Similarly, because A′ ∩ B′ = ∅, g is well-defined.

Let us study g ∘ f. We have:
$$\begin{cases}
    \forall a \in A, \; g(f(a)) = f_A^{-1}(f_A(a)) = a \\
    \forall b \in B, \; g(f(b)) = f_B^{-1}(f_B(b)) = b
\end{cases}$$

Hence, g ∘ f = id_(A ∪ B). Similarly, f ∘ g = id_(A′ ∪ B′). Therefore,
g = f^( − 1), f is a bijection, and A ∪ B ≃ A′ ∪ B′.

We’ll now do a shift in notation. Let be some arbitrary sets A and B.
Let be A₁, A₂, B₁, B₂ such that A₁ = {1} × A, A₂ = {2} × A,
B₁ = {1} × B, and B₂ = {2} × B. This means A ≃ A₁, A ≃ A₂, B ≃ B₁, and
B ≃ B₂. It also means A₁ ∩ A₂ = ∅ and B₁ ∩ B₂ = ∅. From the above, this
implies A₁ ∪ B₁ ≃ A₂ ∪ B₂.

This means that the disjoint union of A and B is indeed well-defined, up
to isomorphism: so long as 2 respective copies of A and B are made in a
way that their intersection is empty, the 2 respective unions of 1 copy
each will be isomorphic.

2.10)

Show that if A and B are finite sets, then |B^(A)| = |B|^(|A|).

The number of |B^(A)| functions in B^(A) = (A → B) can be counted in the
following way.

For each element a of A, of which there are |A|, we can pick any element
of |B| as the image. This means |B| × ... × |B|, a total of |A| times.
Hence, |B^(A)| = |B|^(|A|).

2.11)

In view of Exercise 2.10, it is not unreasonable to use 2^(A) to denote
the set of functions from an arbitrary set A to a set with 2 elements
(say 𝔹 = {0, 1}). Prove that there is a bijection between 2^(A) and the
power set 𝒫(A) of A.

Simply put, every subset A_(i) of A is built through a series of |A|
choices: for each element a in A, do we keep the element a in our subset
A_(i) (output 1) or do we remove it (output 0) ? It is then easy to see
that such a series of choices can easily be encoded as a unique function
in A → 𝔹. The totality of such series of choices thus corresponds both
to the space A → 𝔹, and to the powerset 𝒜, and there is a bijection
between the two.

Section 3)

3.1)

Let 𝒞 be a category. Consider a structure 𝒞^(op) with: -
Obj(𝒞^(op)) ≔ Obj(𝒞); - for A, B objects of 𝒞^(op) (hence, objects of
𝒞), Hom_(𝒞^(op))(A, B) ≔ Hom_(𝒞)(B, A) Show how to make this into a
category.

3.1.a) Composition

First, to make things clearer and more rigorous, let us distinguish
composition in 𝒞 as ∘ and composition in 𝒞^(op) as ⋆. We define ⋆ as:
$$\begin{aligned}
    & \forall f \in Hom_{\mathcal{C}^{op}} (B, A) = Hom_{\mathcal{C}} (A, B), \\
    & \forall g \in Hom_{\mathcal{C}^{op}} (C, B) = Hom_{\mathcal{C}} (B, C), \\
    & \exists h \in Hom_{\mathcal{C}^{op}} (C, A) = Hom_{\mathcal{C}} (A, C), \\
    & f \star g \coloneqq g \circ f = h
\end{aligned}$$

We will now show that 𝒞^(op) with ⋆ verifies the other axioms of a
category (namely identity and assossiativity of composition).

3.1.b) Identity

Since 𝒞 is a category, since 𝒞^(op) has the same objects, and since, by
definition, for all object A, we have
Hom_(𝒞^(op))(A, A) = Hom_(𝒞)(A, A), we can take every
id_(A) ∈ Hom_(𝒞)(A, A) as the same identity in 𝒞^(op). We can verify
that this is compatible with ⋆:

$$\begin{aligned}
    \forall A, B & \in Obj (\mathcal{C})        &=& \;  Obj (\mathcal{C}^{op})        , \\
    \exists id_A & \in Hom_{\mathcal{C}} (A, A) &=& \;  Hom_{\mathcal{C}^{op}} (A, A) , \\
    \exists id_B & \in Hom_{\mathcal{C}} (B, B) &=& \;  Hom_{\mathcal{C}^{op}} (B, B) , \\
    \forall f    & \in Hom_{\mathcal{C}} (A, B) &=& \;  Hom_{\mathcal{C}^{op}} (B, A) , \\
    f            & =   f    \circ id_A          &=& \;  id_A \star f                  , \\
    f            & =   id_B \circ    f          &=& \;  f    \star id_B                 \\
\end{aligned}$$

3.1.c) Associativity

Using associativity in 𝒞, we have:

$$\begin{aligned}
    \forall A, B, C, D & \in Obj (\mathcal{C})        &=& \;  Obj (\mathcal{C}^{op})        , \\
    \forall f          & \in Hom_{\mathcal{C}} (A, B) &=& \;  Hom_{\mathcal{C}^{op}} (B, A) , \\
    \forall g          & \in Hom_{\mathcal{C}} (B, C) &=& \;  Hom_{\mathcal{C}^{op}} (C, B) , \\
    \forall h          & \in Hom_{\mathcal{C}} (C, D) &=& \;  Hom_{\mathcal{C}^{op}} (D, C) , \\
\end{aligned}$$
$$\begin{aligned}
    h \star (g \star f) &=&  h \star (f  \circ g) \\
                        &=& (f \circ  g) \circ h  \\
                        &=&  f \circ  (g \circ h) \\
                        &=&  (g \circ h) \star f  \\
                        &=&  (h \star g) \star f  \\
\end{aligned}$$

Therefore, ⋆ is associative.

We conclude that 𝒞^(op) is a category.

3.2)

If A is a finite set, how large is End_(Set)(A) ?

We know that, in Set, End_(Set)(A) = (A → A) = A^(A). From a previous
exercise, we know that |B^(A)| = |B|^(|)A|, therefore
|End_(Set)(A)| = |A|^(|)A|.

3.3)

Formulate precisely what it means to say that "1_(a) is an identity with
respect to composition" in Example 3.3, and prove this assertion.

Example 3.3 is that of a category over a set S with a (reflexive,
transitive) relation ∼, where the objects of the category are the
elements of S, and the homset between two elements a and b is the
singleton (a, b) if a ∼ b, and ∅ otherwise. Composition ∘ is given by
transitivity of ∼, where (b, c) ∘ (a, b) = (a, c). Reflexivity gives the
identities (id_(a) = (a, a) for any element a).

In this context, to say that "1_(a) is an identity with respect to
composition" means that we can cancel out an element of the form (a, a)
from a composition.

Formally, we have:

∀a, b ∈ S, (b, b) ∘ (a, b) = (a, b) = (a, b) ∘ (a, a)

proving that (b, b) is indeed a post-identity, and (a, a) a
pre-identity, in this context.

3.4)

Can we define a category in the style of Example 3.3, using the relation
< on the set ℤ ?

(Description of example 3.3 in the exercise 3.3 just above.)

Naively, saying like in example 3.3 "there is a singleton homset
Hom(a, b) each time we have a < b", we cannot define such a category,
since < is not reflexive, and we would thus lack identity morphisms.

However, in a roundabout way, we can define a category over the negation
of <: "there is a singleton homset Hom(a, b) each time we DO NOT have
a < b". Namely this corresponds to the relation ≥, which is, itself,
reflexive, transitive (and antisymmetric), and is a valid instance of
the kind of category presented in example 3.3.

In fact, the pair (ℤ,  ≥ ) is an instance of what is called a "totally
ordered set", which is a more restrictive kind of "partially ordered
set" (also called "poset" for short). Consequently, this kind of
category is called a "poset category".

3.5)

Explain in what sense Example 3.4 is an instance of the categories
considered in Example 3.3.

(Description of example 3.3 in the exercise 3.3 just above.)

Example 3.4 describes a category Ŝ where the objects are the subsets of
a set S (equivalently: elements of the powerset 𝒫(S) of S), and
morphisms between two subsets A and B of S are singleton (or empty)
homsets based on whether the inclusion is true (or false).

Inclusion of sets, ⊂, is also an order relation, this time between the
elements of a set of sets (here, 𝒫(S)). This means inclusion is
reflexive, transitive, and antisymmetric. This makes Ŝ a poset category,
and thus another instance of example 3.3.

3.6)

Define a category V by taking Obj(V) = ℕ, and
Hom_(V)(n, m) = Mat_(ℝ)(m, n), the set of m × n matrices with real
entries, for all n, m ∈ ℕ. (I will leave the reader the task to make
sense of a matrix with 0 rows or columns.) Use product of matrices to
define composition. Does this category ’feel’ familiar ?

The formulation of the exercise is strange. It says to use the product
of matrices to define composition, and to have homsets be sets of
matrices, but objects of the category are supposed to be integers. I
don’t know of any matrix with real entries that maps an integer to an
integer in this way.

We thus infer that the meaning of the exercise can be one of two things.

Either we suppose the set of objects could rather be understood as
"something isomorphic to ℕ", ie, the collection of real vector spaces
with finite bases (ie, ∀n ∈ ℕ, ℝ^(n)). In which case, this is just the
category of real vector spaces with finite basis (and linear maps as
morphisms), which is a subcategory of the category real vector spaces
(commonly called Vect_(ℝ)). In this context, any morphism starting from
0 ≃ ℝ⁰ = {0} is just the injection of the origin into the codomain; and
any morphism ending at 0 is the mapping of all elements to the origin.

Otherwise, we understand this as "yes, the objects of the category are
integers: this means you should ignore the actual content of the
matrices, and instead consider only their effect on the dimensionality
of domains and codomains". In this case, this category is a complete
directed graph over ℕ where each edge corresponds to the change in
dimension (from domain to codomain) caused by a given linear map.

3.7)

Define carefully objects and morphisms in Example 3.7, and draw the
diagram corresponding to composition.

Example 3.7 (on coslice categories) refers to example 3.5 (on slice
categories). Let’s go over slice categories (since example 3.5 asks the
reader to "check all [their various properties]").

3.7.1) Slice categories

Slice categories are categories made by singling out an object (say A)
in some parent (larger) category (say 𝒞), and studying all morphisms
into that object. These morphisms become the objects of a new category
(ie, for any Z of 𝒞, f ∈ (Z → A) is an object of the slice category,
called 𝒞_(A) in this context). In the slice category, morphisms are
defined as those morphism in 𝒞 that preserve composition between 2
morphisms into A.

Note that there exist pairs of morphisms f₁ ∈ (Z₁ → A) and f₂ ∈ (Z₂ → A)
between which there is no morphism that exists in the slice category.
One such example we can make is in (Vect_(ℝ))_(ℝ²). If we take the maps:

$$f_1 = \begin{bmatrix} 1 & 0 \\ 0 & 0 \end{bmatrix} \in \mathcal{L}(\mathbb{R}^2)$$
$$f_2 = \begin{bmatrix} 0 & 0 \\ 0 & 1 \end{bmatrix} \in \mathcal{L}(\mathbb{R}^2)$$

There exists no map σ such that the following diagram commutes (since
the output of f₁ will always be null in its second coordinate, and the
output of f₂ will always be null in the first):

Now, let us prove that 𝒞_(A) is indeed a category for an arbitrary
object A of an arbitrary category 𝒞.

3.7.1.a) Identity

A generic identity morphism is expressed diagrammatically in 𝒞_(A) as:

We can see that since f = f ∘ id_(Z) in 𝒞, this is compatible with the
definition of a (pre-/right-)unit morphism in 𝒞_(A). Also, since the
only maps post-f are maps from A → A, we have id_(A) as the
(post-/left-)unit for every morphism f (ie, f = id_(A) ∘ f.

3.7.1.b) Composition

Taking 3 objects of the slice category (f₁ ∈ (Z₁ → A), f₂ ∈ (Z₂ → A) and
f₃ ∈ (Z₃ → A)), and two morphisms (σ_(A) mapping f₁ to f₂ via a
𝒞-morphism σ ∈ (Z₁ → Z₂), and τ_(A) mapping f₂ to f₃ via a 𝒞-morphism
τ ∈ (Z₂ → Z₃)), we have that f₁ = f₂ ∘ σ and f₂ = f₃ ∘ τ. This is
expressed as the following commutative diagram.

Composition of morphisms is then defined as τ_(A)∘_(A)σ_(A) as a mapping
from f₁ to f₃, such that f₁ = f₃ ∘ (τ ∘ σ). This can be understood
through the following commutative diagram:

Which commutes, because we have:

$$\begin{aligned}
    f_1 &=&  f_2              \circ \sigma  \\
        &=& (f_3 \circ  \tau) \circ \sigma  \\
        &=&  f_3 \circ (\tau  \circ \sigma)
\end{aligned}$$

Thus, we have a working composition of morphisms.

3.7.1.c) Associativity

We take 4 objects of the slice category (f₁ ∈ (Z₁ → A), f₂ ∈ (Z₂ → A),
f₃ ∈ (Z₃ → A) and f₄ ∈ (Z₄ → A)), and three morphisms (σ_(A) mapping f₁
to f₂, τ_(A) mapping f₂ to f₃, and υ_(A) mapping f₃ to f₄). Using
composition defined as above, we have

$$\begin{aligned}
f_1 &=& f_4 \circ ( \upsilon \circ (\tau  \circ \sigma)) \\
    &=& f_4 \circ ((\upsilon \circ  \tau) \circ \sigma ) \\
\Rightarrow && \\
& &  \upsilon_A \circ (\tau_A  \circ \sigma_A) \\
&=& (\upsilon_A \circ  \tau_A) \circ \sigma_A
\end{aligned}$$

Through associativity in 𝒞.

3.7.2) Coslice categories

A coslice category 𝒞^(A) is similar, except it takes the morphisms
coming from a chosen object A, rather than those going to this object A.
Below is a commutative diagram in the style of the one of the textbook
for slice categories.

We can similarly show that this also defines a category.

3.7.2.a) Identity

A generic identity morphism is expressed diagrammatically in 𝒞^(A) as:

We can see that since f = id_(Z) ∘ f in 𝒞, this is compatible with the
definition of a (post-/left-)unit morphism in 𝒞^(A). Also, since the
only maps pre-f are maps from A → A, we have id_(A) as the
(pre-/right-)unit for every morphism f (ie, f = f ∘ id_(A).

3.7.2.b) Composition

Taking 3 objects of the slice category (f₁ ∈ (A → Z₁), f₂ ∈ (A → Z₂) and
f₃ ∈ (A → Z₃)), and two morphisms (σ^(A) mapping f₁ to f₂ via a
𝒞-morphism σ ∈ (Z₁ → Z₂), and τ^(A) mapping f₂ to f₃ via a 𝒞-morphism
τ ∈ (Z₂ → Z₃)), we have that f₁ = σ ∘ f₂ and f₂ = τ ∘ f₃. This is
expressed as the following commutative diagram.

Composition of morphisms is then defined as τ^(A)∘^(A)σ^(A) as a mapping
from f₁ to f₃, such that f₃ = (τ ∘ σ) ∘ f₁. This can be understood
through the following commutative diagram:

Which commutes, because we have:

$$\begin{aligned}
    f_3 &=&  \tau \circ                f_2  \\
        &=&  \tau \circ (\sigma  \circ f_1) \\
        &=& (\tau \circ  \sigma) \circ f_1
\end{aligned}$$

Thus, we have a working composition of morphisms.

3.7.2.c) Associativity

We take 4 objects of the slice category (f₁ ∈ (A → Z₁), f₂ ∈ (A → Z₂),
f₃ ∈ (A → Z₃) and f₄ ∈ (A → Z₄)), and three morphisms (σ^(A) mapping f₁
to f₂, τ^(A) mapping f₂ to f₃, and υ^(A) mapping f₃ to f₄). Using
composition defined as above, we have

$$\begin{aligned}
f_4 &=& ( \upsilon \circ (\tau  \circ \sigma)) \circ f_1 \\
    &=& ((\upsilon \circ  \tau) \circ \sigma ) \circ f_1 \\
\Rightarrow && \\
    & &  \upsilon^A \circ (\tau^A  \circ \sigma^A) \\
    &=& (\upsilon^A \circ  \tau^A) \circ \sigma^A
\end{aligned}$$

Through associativity in 𝒞.

3.8)

A subcategory 𝒞′ of a category 𝒞 consists of a collection of objects of
𝒞, with morphisms Hom_(𝒞′)(A, B) ⊆ Hom_(𝒞)(A, B) for all objects A, B in
Obj(𝒞′), such that identities and compositions in 𝒞 make 𝒞′ into a
category. A subcategory 𝒞′ is full if Hom_(𝒞′)(A, B) = Hom_(𝒞)(A, B) for
all A, B in Obj(𝒞′). Construct a category of infinite sets and explain
how it may be viewed as a full subcategory of Set.

To put it less technically, a "subcategory" 𝒞′ is just "picking only
certain items of a base category 𝒞, and making sure that things stay
closed uneder morphism composition". It is "full" if all morphisms
between the objects that remain are also conserved.

We can construct a category InfSet of infinite sets by taking all the
objects A of Set such that ∄n ∈ ℕ, |A| = n, and only homsets between
these objects. This is clearly a subcategory of Set, since it inherits
all identity morphisms, composition works the same, and so does
associativity; also, restricting the choice of homsets makes it so that
the category is closed (you can’t reach a finite set via a homset that
went from an infinite to a finite set).

For this category to not be full, there would need to be some homset
that loses a morphism, or fully disappears, in the ordeal. However,
there is no restriction as to the kind of morphism that is conserved, so
any homset that is kept is identical to its original version. Finally,
homsets between infinite sets are also infinite sets, so they don’t
disappear in this operation.

Consequently InfSet defined as such is a full subcategory of Set.

3.9)

An alternative to the notion of multiset introduced in §2.2 is obtained
by considering sets endowed with equivalence relations; equivalent
elements are taken to be multiple instances of elements ’of the same
kind’. Define a notion of morphism between such enhanced sets, obtaining
a category MSet containing (a ’copy’ of) Set as a full subcategory.
(There may be more than one reasonable way to do this! This is
intentionally an open-ended exercise.) Which objects in MSet determine
ordinary multisets as defined in §2.2, and how? Spell out what a
morphism of multisets would be from this point of view. (There are
several natural notions of morphisms of multisets. Try to define
morphisms in MSet so that the notion you obtain for ordinary multisets
captures your intuitive understanding of these objects.) [§2.2, §3.2,
4.5]

Let us recall how multisets were defined in §2.2. Since duplicate
elements do not exist in sets, multisets were instead defined as
functions from a set S to ℕ*, the set of (nonzero) positive integers.
This allows each element in S to have a "count", thereby encoding the
intuitive notion of multiset. A similar, and equivalent (isomorphic),
way of defining it is via pairs (s, n) ∈ S × ℕ*, which is simpler to
think about. We’ll call this category CMSet, for "count multiset" (TODO:
probably has a conventional and better name, but I don’t know it). As
for morphisms in CMSet, we can consider that for any multisets
A = S_(A) × ℕ* and B = S_(B) × ℕ*, the homset from A to B is simply the
set functions from S_(A) × ℕ* to S_(B) × ℕ* as usual.

We first notice that if we restrict CMSet to only the objects for which
all elements have a count of 1, and where morphisms only ever output to
{1} in the second coordinate (a subcategory we can call C1MSet, for
example), we get a "copy" of Set: C1MSet and Set are isomorphic in Cat.
This is a full subcategory because there are no morphisms that map
counts to anything else than {1} if we restrict our objects to this
form; so all morphisms between the kept objects are also kept.

Now let us do a similar construction, but based on equivalence classes
instead. We know that each equivalence class over a set corresponds
uniquely to a partition of that set. By considering only these
partitions (these "sets of sets") as objects, we can build a category
EMSet (for "equivalence multiset"). The "count" corresponds simply to
the cardinal of a top-level element in the partition. For example, the
top-level elements of M = {S₁, S₂, S₃} = {{a}, {b, c}, {d, e, f}} would
be understood to have counts |S₁| = 1, |S₂| = 2 and |S₃| = 3
respectively.

As for morphisms in EMSet, they simply map each top-level element of the
domain multiset (a distinct subset of the original set) to some other
top-level elements in the codomain multiset. This has precisely the same
effect as mapping pairs of "value and count" as seen in the previous
CMSet construction.

In this example, any set itself, when "injected" (by a functor) into
EMSet would just nest all of its elements into singletons. I.e.,
S = {a, b, c} in Set would become S = {{a}, {b}, {c}} in EMSet. This
also shows how restricting EMSet to "only objects that are a set of
(toplevel) singletons" makes EMSet have a "copy" of Set as a full
subcategory (for similar arguments as above).

Yet another example could be something akin to polynomials with integer
coefficients on freeform indeterminates of degree 1 (which would be our
set elements); raising the operators one rank, a product of freeform
variables with integer powers (multiplicities), etc.

3.10)

Since the objects of a category 𝒞 are not (necessarily) sets, it is not
clear how to make sense of a notion of ’subobject’ in general. In some
situations it does make sense to talk about subobjects, and the
subobjects of any given object A in 𝒞 are in one-to-one correspondence
with the morphisms A → Ω for a fixed, special object Ω of 𝒞, called a
subobject classifier. Show that Set has a subobject classifier.

We define the set 𝔹 = {0, 1}, aka the binary alphabet or booleans, as
the subobject classifier of Set. For any subset A of B, there is a
unique map f : B → 𝔹, such that ∀b ∈ B, f(b) = 1 ⇔ b ∈ A (otherwise
f(b) = 0, of course, as the equivalence and lack of alternatives to 0 as
an output imply). The map f always fully describes A from its
relationship with B.

3.11)

Draw the relevant diagrams and define composition and identities for the
category 𝒞^(A, B) mentioned in Example 3.9. Do the same for the category
𝒞^(α, β) mentioned in Example 3.10. [§5.5, 5.12]

For lack of a better term, we will refer to the categories of the form
𝒞_(A, B) represented by Example 3.9 as "bi-slice categories". The first
part of the exercise is thus asking us to define and explain what
"bi-coslice categories" (of the form 𝒞^(A, B)) are.

Similarly, we will refer to the categories of the form 𝒞_(α, β)
represented by Example 3.10 as "fibered bi-slice categories". The second
part of the exercise is thus asking us to define and explain what
"fibered bi-coslice categories" (of the form 𝒞^(α, β)) are.

We will, of course, attempt to make more formal and pedagogical all
definitions broached in the textbook’s examples as well.

3.11.1) Bi-slice categories

3.11.1.a) Objects and morphisms

To make a bi-slice category 𝒞_(A, B), we pick 2 objects A and B of a
base category 𝒞, and consider for all other objects Z of 𝒞, all pairs of
morphisms (f, g) ∈ (Z → A) × (Z → B). These pairs of morphisms are the
objects of the bi-slice category 𝒞_(A, B). Morphisms σ_(A, B) are
defined from an object p₁ = (f₁, g₁) ∈ (Z₁ → A) × (Z₁ → B) to an object
p₂ = (f₂, g₂) ∈ (Z₂ → A) × (Z₂ → B) so that we have both f₁ = f₂ ∘ σ and
g₁ = g₂ ∘ σ, for some σ ∈ (Z₁ → Z₂).

A generic object in 𝒞_(A, B) is of the form:

3.11.1.b) Morphisms

Morphisms are defined between objects as

such that the following diagram commutes

3.11.1.c) Identity

It is clear that identity morphisms exist for all objects, simply by
taking Z = Z₁ = Z₂, f₁ = f₂, g₁ = g₂ and σ = id_(Z), in the diagram
above.

3.11.1.d) Composition

Let be 3 objects of 𝒞_(A, B), which we will name p₁, p₂ and p₃ (and
define with the respective (Z_(n), f_(n), g_(n)) triplet for p_(n)).

Composition τ_(A, B) ∘ σ_(A, B) = p₁ ↦ p₃ of two morphisms
σ_(A, B) = p₁ ↦ p₂ and τ_(A, B) = p₂ ↦ p₃ is defined so that the
following diagram commutes.

3.11.1.e) Associativity

Associativity follows from associativity of morphisms in 𝒞, similarly to
what was done for slice categories in exercise 3.7 .

3.11.2) Bi-coslice categories

3.11.2.a) Objects and morphisms

To make a bi-coslice category 𝒞^(A, B), we similarly pick 2 objects A
and B of our base category 𝒞, but instead consider, for all other
objects Z of 𝒞, all pairs of morphisms (f, g) ∈ (A → Z) × (B → Z).

A generic object in 𝒞^(A, B) is of the form:

3.11.2.b) Morphisms

Morphisms are defined between objects as

such that the following diagram commutes

3.11.2.c) Identity

It is clear that identity morphisms exist for all objects, simply by
taking Z = Z₁ = Z₂, f₁ = f₂, g₁ = g₂ and σ = id_(Z), in the diagram
above.

3.11.2.d) Composition

Let be 3 objects of 𝒞^(A, B), which we will name p₁, p₂ and p₃ (and
define with the respective (Z_(n), f_(n), g_(n)) triplet for p_(n)).

Composition τ^(A, B) ∘ σ^(A, B) = p₁ ↦ p₃ of two morphisms
σ^(A, B) = p₁ ↦ p₂ and τ^(A, B) = p₂ ↦ p₃ is defined so that the
following diagram commutes.

3.11.2.e) Associativity

Associativity follows from associativity of morphisms in 𝒞, similarly to
what was done for slice categories in exercise 3.7 .

3.11.3) Fibered bi-slice categories

3.11.3.a) Objects

To build a fibered bi-slice category 𝒞_(α, β), one takes a base category
𝒞, as well as a fixed pair of morphisms α : A → C and β : B → C in 𝒞,
that point to a common object C of 𝒞. Our basic "fixed construct" from 𝒞
looks like so:

The role of the category 𝒞_(α, β) is now to study the morphisms into
this construct. A generic object from this new category looks like so:

such that the diagram commutes. This means that valid object in 𝒞_(α, β)
are triplets (Z, f, g), with f : Z → A and g : Z → B, such that
α ∘ f = β ∘ g. In a caricatural way, this boils down to studying "the
comparison of the different paths one can use to reach C, knowing that
the last steps are on one hand, α, and on the other, β".

3.11.3.b) Morphisms

Morphisms are defined between objects as:

such that the following diagram commutes

3.11.3.c) Identity

Once again, it is clear that identity morphisms exist for all objects,
simply by taking Z = Z₁ = Z₂, f₁ = f₂, g₁ = g₂ and σ = id_(Z), in the
diagram above.

3.11.3.d) Composition

Let be 3 objects of 𝒞_(α, β), which we will name p₁, p₂ and p₃ (and
define with the respective (Z_(n), f_(n), g_(n)) triplet for p_(n)).

Composition τ_(α, β) ∘ σ_(α, β) = p₁ ↦ p₃ of two morphisms
σ_(α, β) = p₁ ↦ p₂ and τ_(α, β) = p₂ ↦ p₃ is defined so that the
following diagram commutes.

3.11.3.e) Associativity

Associativity follows from associativity of morphisms in 𝒞, similarly to
what was done for slice categories in exercise 3.7 .

3.11.4) Fibered bi-coslice categories

3.11.4.a) Objects

To build a fibered bi-coslice category 𝒞^(α, β), one takes a base
category 𝒞, as well as a fixed pair of morphisms α : C → A and β : C → B
in 𝒞, that originate from a common object C of 𝒞. Our basic "fixed
construct" from 𝒞 looks like so:

The role of the category 𝒞^(α, β) is now to study the morphisms from
this construct. A generic object from this new category looks like so:

such that the diagram commutes. This means that valid object in 𝒞^(α, β)
are triplets (Z, f, g), with f : A → Z and g : B → Z, such that
f ∘ α = g ∘ β. In a caricatural way, this boils down to studying "the
comparison of the different paths one can build by starting from C,
knowing that the choice of first step is on one hand, α, and on the
other, β".

3.11.4.b) Morphisms

Morphisms are defined between objects as:

such that the following diagram commutes

3.11.4.c) Identity

Once again, it is clear that identity morphisms exist for all objects,
simply by taking Z = Z₁ = Z₂, f₁ = f₂, g₁ = g₂ and σ = id_(Z), in the
diagram above.

3.11.4.d) Composition

Let be 3 objects of 𝒞^(α, β), which we will name p₁, p₂ and p₃ (and
define with the respective (Z_(n), f_(n), g_(n)) triplet for p_(n)).

Composition τ^(α, β) ∘ σ^(α, β) = p₁ ↦ p₃ of two morphisms
σ^(α, β) = p₁ ↦ p₂ and τ^(α, β) = p₂ ↦ p₃ is defined so that the
following diagram commutes.

3.11.4.e) Associativity

Associativity follows from associativity of morphisms in 𝒞, similarly to
what was done for slice categories in exercise 3.7 .

Section 4)

4.1)

Composition is defined for two morphisms. If more than 2 morphisms are
given, one may compose them in several ways, so that every step only
consists in composing 2 morphisms. Prove that for any such valid
sequence of morphisms, the order of parentheses doesn’t matter.

This boils down to showing that associativity is a global property, that
doesn’t just make parentheses meaningless when there are 3 elements and
2 operators between them, but in general n elements with (n − 1)
operators between them.

Note: A useful way of visualizing this is representing the order of
operations as a binary tree, and noticing that applying associativity
(forwards or backwards) is just a tree rotation (resp. right or left) at
a given node. Then it is easy to show that one can always obtain a "left
comb binary tree". Since every choice of parentheses is equal to this
left comb choice, and equality is transitive, every choice of
parentheses is equal to every other choice.

To be more rigorous, we will proceed by induction.

Hypothesis: P(n) = "for a given n, for f_(n)f_(n − 1) ⋅ f₁ any valid,
composable, ordered sequence of morphisms in our base category 𝒞, any
choice H of parentheses to compose elements of this sequence 2-by-2,
giving a formula s_(H), will lead to the same result, which can be seen
by always having s_(H) = ( ⋅ (f_(n)f_(n − 1)) ⋅ )f₁".

Initialization: We initialize at n = 3; the validity is immediate as it
is precisely the definition of associativity.

Heredity: We suppose the hypothesis P(n) true for a given n ≥ 3; let us
show that this implies that the hypothesis is true for P(n + 1).

What this means is that, no matter the composable ordered sequence
f_(n)f_(n − 1) ⋅ f₁ of n functions, for a fixed n, the order of
parentheses does not matter. Note that though n is chosen and fixed; the
statement is true for EVERY (ordered, composable) sequence of functions.
We add a new function g to this sequence. By a simple renaming of the
functions, we deduce that it doesn’t matter where we insert g, so we’ll
insert it at the very right to simplify our argument, giving us the
sequence f_(n)f_(n − 1) ⋅ f₁g.

Here, there are 3 cases. Either:

-   g is part of the last composition (i.e., it’s not in a semantically
    necessary parenthethical grouping; it can be made external to all
    parentheses),

-   g is part of the first composition (i.e., the first operation is
    (f₁g))

-   it isn’t either (it’s inside some non-removable parentheses, and
    needs to be composed earlier on, but not as the first operation).

If g is part of the last composition, then by applying the hypothesis
P(n) to the terms f_(n)f_(n − 1) ⋅ f₁, we immediately find that our new
sequence can be made equal to (( ⋅ (f_(n)f_(n − 1)) ⋅ )f₁)g, which is
precisely what we wanted for P(n + 1).

If g is part of the first composition, we isolate it so that it isn’t
anymore. To do so, we apply "backwards" associativity on the grouping of
terms F_(k)(f₁g) in order to obtain (F_(k)f₁)g, where F_(k) is the
appropriate choice of (f_(k) ⋅ f₂) such that associativity can be
applied (with 2 ≤ k ≤ n). This makes it so that our problem is identical
to our final case, solved just below.

If g is part of neither the first nor last composition, then we consider
the innermost composition (f_(k)f_(k − 1)) to be a single element h. We
now have a sequence of only n terms. We apply our hypothesis P(n). This
makes g the outermost right term, part of the last composition.
Unravelling h back into two members, we see that we are back at our
initial case, with an arbitrary order of parentheses for the
f_(n)f_(n − 1) ⋅ f₁ terms, and g outermost. We already saw that this
implied P(n + 1).

Conclusion: since we have initialization and heredity of our hypothesis
in all cases, we can conclude by induction that it is true for all
n ≥ 3.

4.2)

In Example 3.3 we have seen how to construct a category from a set
endowed with a relation, provided the latter is reflexive and
transitive. For what types of relations is the corresponding category a
groupoid (cf. Example 4.6) ?

We remind example 4.6 : a groupoid is a category in which every morphism
is an isomorphism. This means that every morphism needs to be 2-way
invertible.

In this context, this means that for every morphism a ∼ b, there should
be a corresponding inverse morphism b ∼ a. This property is precisely
the symmetry of a relation.

This means that all sets with an equivalence relation can be
reconstructed into a groupoid.

4.3)

Let A, B be objects of a category 𝒞, and f ∈ Hom_(𝒞)(A, B) a morphism.
Prove that if f has a pre-inverse, then f is an epimorphism. Show that
the converse does not hold, by giving an explicit example of a category
and an epimorphism without a pre-inverse.

4.3.a)

f has a pre-inverse ⇒ f is an epimorphism

Let 𝒞 be a category. Let f ∈ Hom_(𝒞)(A, B), having some pre-inverse
which we’ll call g ∈ Hom_(𝒞)(B, A):

Let Z be an arbitrary object of 𝒞, and
$\beta', \beta" \in Hom_{\mathcal{C}} (B, Z)$:

$$\begin{aligned}
    \beta' \circ f = \beta'' \circ f
        & \Rightarrow (\beta' \circ  f) \circ g  = (\beta'' \circ  f) \circ g  \\
        & =            \beta' \circ (f  \circ g) =  \beta'' \circ (f  \circ g) \\
        & =            \beta' \circ id_B         =  \beta'' \circ id_B \\
        & =            \beta'                    =  \beta''
\end{aligned}$$

This means that f is an epimorphism.

4.3.b)

f is an epimorphism $\;\not\!\!\!\Rightarrow$ f has a pre-inverse

As was mentioned in the text, "order" categories (poset categories)
where there’s only at most one morphism between any two objects makes it
so that every morphism is trivially an epimorphism. However, only
identities have any kind of inverse (since they are isomorphisms, they
are their own inverse).

See also here and here.

4.4)

Prove that the composition of two monomorphisms is a monomorphism.
Deduce that one can define a subcategory 𝒞_(mono) of a category 𝒞 by
taking the same objects as in 𝒞, and defining Hom_(𝒞_(mono))(A, B) to be
the subset of Hom_(𝒞)(A, B) consisting of monomorphisms, for all objects
A, B. (Cf. Exercise 3.8; of course, in general 𝒞_(mono) is not full in
𝒞.) Do the same for epimorphisms. Can you define a subcategory
𝒞_(nonmono) of 𝒞 by restricting to morphisms that are not monomorphisms?

4.4.a)

Mono

Let be f ∈ Hom_(𝒞)(A, B) and g ∈ Hom_(𝒞)(B, C) be monomorphisms. Let us
show that g ∘ f is also a monomorphism.

Let Z be an arbitrary object of 𝒞, and
$\alpha', \alpha" \in Hom_{\mathcal{A}} (Z, A)$:

$$\begin{aligned}
    (g \circ f) \circ \alpha' = (g \circ f) \circ \alpha''
        & = g \circ (f \circ \alpha') = g \circ (f \circ \alpha'') \\
        & \Rightarrow f \circ \alpha' = f \circ \alpha'' \text{ because $g$ is mono} \\
        & \Rightarrow         \alpha' =         \alpha'' \text{ because $f$ is mono}
\end{aligned}$$

This means that the composition of 2 monomorphisms is always an
monomorphism. We can thus make a subcategory. Taking all objects,
properties, and homsets of 𝒞, but restricting the homsets only to the
monomorphisms, we know that this makes a new category 𝒞_(mono) since it
is closed under composition, has identities (which are iso, and a
fortiori mono) and associativity.

4.4.b)

Epi

Let be f ∈ Hom_(𝒞)(A, B) and g ∈ Hom_(𝒞)(B, C) be epimorphisms. Let us
show that g ∘ f is also a epimorphism.

Let Z be an arbitrary object of 𝒞, and
$\beta', \beta" \in Hom_{\mathcal{C}} (C, Z)$:

$$\begin{aligned}
    \beta' \circ (g \circ f) = \beta'' \circ (g \circ f)
        & = (\beta' \circ g) \circ f = (\beta'' \circ g) \circ f \\
        & \Rightarrow \beta' \circ g =  \beta'' \circ g \text{ because $f$ is epi} \\
        & \Rightarrow \beta'         =  \beta''         \text{ because $g$ is epi}
\end{aligned}$$

This means that the composition of 2 epimorphisms is always an
epimorphism. We can thus make a subcategory. Taking all objects,
properties, and homsets of 𝒞, but restricting the homsets only to the
epimorphisms, we know that this makes a new category 𝒞_(epi) since it is
closed under composition, has identities (which are iso, and a fortiori
epi) and associativity.

4.4.c)

Nonmono and nonepi

We could consider the fact that (TODO prove lol) we can’t obtain a
monomorphism from the composition of two non-monomorphisms (you need at
least one monomorphism in the mix). However, the real problem is
identities. Identities are iso, and thus mono. You can’t make a category
without identities, so there is no such 𝒞_(nonmono). the same reasoning
applies to 𝒞_(nonepi).

4.5)

Give a concrete description of monomorphisms and epimorphisms in the
category MSet you constructed in Exercise 3.9. (Your answer will depend
on the notion of morphism you defined in that exercise!)

We’ll use our CMSet construction, where elements of multisets consisted
of a pair of the set-element and its count in the multiset.

We recall that in the way we formulated this, morphisms were just simple
set functions on "(element, count)" pairs (i.e., returning any other
"(element, count)" pair of the codomain). Let be a morphism of multisets
f ∈ (A → B). Labelling the elements of the domain A as a_(i) and of the
codomain B as b_(j) with i ∈ I, j ∈ J, and I, J any two indexing sets
such that card(A) = card(I) and card(B) = card(J), we can see that A and
B now just look like "normal" sets.

We now simply recycle the notion of injections and surjections. These
form our monomorphisms and epimorphisms respectively.

Extra exercises by/for the group

Chapter I) 1) Set notation)

Write the following in set notation (as a list of numbers, and
algebraically):

-   the set of all odd integers

-   the set of all integers that are not multiples of 3

-   the set of integers from 10 (included) to 20 (included)

-   the set of integers from 10 (included) to 20 (excluded)

-   the set of pairs of integers with both elements of the same value

-   the set of triplets of real numbers that together sum to 1

-   the set of pairs of positive real numbers that together sum to 1

-   the set of n-tuplets (for any n) of real number that together sum to
    1

-   the set of all natural numbers such that there exists at least one
    triplet of positive even numbers which are all different and which
    sum to that number.

Now take the sets in their algebraic notation, and represent them both
as a list of numbers (as a logical sequence or just a couple of
examples), and as a "description" of what they are:

-   {3n + 2 | n ∈ ℕ}

-   {3k + 2 | k ∈ ℤ}

-   {2^(i) | i ∈ [[0, 10]]}

-   {(x, y) ∈ ℝ² | x² + y² = 1}

-   {x ∈ ℝ |  − 2 ≤ x ≤ 2}

-   {(m, n, p) ∈ ℕ³ | m + n + p = 10}
